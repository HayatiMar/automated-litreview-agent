{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Automated Literature Review Agent\n\n**Capstone Project ‚Äî Google 5-Day AI Agents Intensive**\n\nThis project implements an AI-driven multi-agent system that:\n\n1. Asks the user for a research topic  \n2. Searches top computational biology journals  \n3. Retrieves the latest relevant papers  \n4. Summarizes them using Google Gemini  \n5. Converts summaries into *blog-ready articles*  \n\nThe system simulates a research assistant capable of literature review, scientific summarization, and blog article generation.\n","metadata":{}},{"cell_type":"markdown","source":"# Section 1 ‚Äî Installation and Configuration","metadata":{}},{"cell_type":"code","source":"## Install Dependencies if needed\n\n!pip install google-generativeai python-dotenv fpdf requests beautifulsoup4 ddgs\nprint(\"‚úÖ Dependencies installed.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T06:32:17.003384Z","iopub.execute_input":"2025-11-30T06:32:17.003723Z","iopub.status.idle":"2025-11-30T06:32:21.392385Z","shell.execute_reply.started":"2025-11-30T06:32:17.003698Z","shell.execute_reply":"2025-11-30T06:32:21.391078Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\nRequirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.2.1)\nRequirement already satisfied: fpdf in /usr/local/lib/python3.11/dist-packages (1.7.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.5)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\nRequirement already satisfied: ddgs in /usr/local/lib/python3.11/dist-packages (9.9.2)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.28.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.177.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.12.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.15.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.10.5)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from ddgs) (8.3.0)\nRequirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from ddgs) (0.15.0)\nRequirement already satisfied: lxml>=4.9.4 in /usr/local/lib/python3.11/dist-packages (from ddgs) (5.4.0)\nRequirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\nRequirement already satisfied: fake-useragent>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from ddgs) (2.2.0)\nRequirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\nRequirement already satisfied: brotli in /usr/local/lib/python3.11/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.1.0)\nRequirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\nRequirement already satisfied: socksio==1.* in /usr/local/lib/python3.11/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.0)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.2)\nRequirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\nRequirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\nRequirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\nRequirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.3.1)\n‚úÖ Dependencies installed.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# 1 - Configuration\nimport os\nimport re\nimport requests\nimport google.generativeai as genai\nfrom ddgs import DDGS\nfrom IPython.display import Markdown\nimport json\nfrom bs4 import BeautifulSoup\nfrom typing import Dict, List\nprint(\"‚úÖ Configuration complete.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T06:37:40.707613Z","iopub.execute_input":"2025-11-30T06:37:40.708751Z","iopub.status.idle":"2025-11-30T06:37:40.715036Z","shell.execute_reply.started":"2025-11-30T06:37:40.708714Z","shell.execute_reply":"2025-11-30T06:37:40.713687Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Configuration complete.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Setup and authentication complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2025-11-30T06:32:30.256042Z","iopub.execute_input":"2025-11-30T06:32:30.256513Z","iopub.status.idle":"2025-11-30T06:32:30.375295Z","shell.execute_reply.started":"2025-11-30T06:32:30.256486Z","shell.execute_reply":"2025-11-30T06:32:30.373777Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Setup and authentication complete.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"if \"GOOGLE_API_KEY\" not in os.environ:\n    raise ValueError(\"‚ùå GOOGLE_API_KEY missing. Make sure secrets were loaded.\")\n\ngenai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\nprint(\"‚úÖ Gemini API configured successfully!\")","metadata":{"execution":{"iopub.status.busy":"2025-11-30T06:32:32.736729Z","iopub.execute_input":"2025-11-30T06:32:32.737061Z","iopub.status.idle":"2025-11-30T06:32:32.742703Z","shell.execute_reply.started":"2025-11-30T06:32:32.737020Z","shell.execute_reply":"2025-11-30T06:32:32.741660Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API configured successfully!\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# Section 2 ‚Äî System Architecture\n\n### 1. **User Interaction Agent**\n- Prompts the user: *\"What subject are you interested in?\"*  \n- Sends the selected topic to the Search Agent.  \n- Initiates the end-to-end workflow.\n\n---\n\n### 2. **Search Agent**\nSearches top open-access computational biology and public-health journals, such as:\n\n- PLOS Computational Biology  \n- eLife  \n- bioRxiv ‚Äì Computational Biology  \n- Genome Research  \n- Bioinformatics  \n- Nature Biotechnology (when open-access)\n\nIt generates queries like:\n\n> \"infectious disease modeling\"  \n> \"antimicrobial resistance transmission\"\n\nReturns candidate papers with titles, URLs, and metadata.\n\n---\n\n### 3. **Extraction Agent**\nRetrieves and cleans scientific content from each article:\n\n- Downloads HTML using `requests`  \n- Extracts readable text with `BeautifulSoup`  \n- Removes menus, navigation bars, and boilerplate  \n- Returns clean, structured text  \n\nIf text cannot be accessed, the agent skips the paper automatically.\n\n---\n\n### 4. **Summarization Agent**\nUses **Gemini 2.5 Flash** to produce structured scientific summaries:\n\n- ~200-word explanation  \n- Core methods  \n- Key findings  \n- Scientific significance  \n\nSummaries are optimized for clarity and accuracy.\n\n---\n\n### 5. **Evaluation Agent**\nPerforms quality checks before a summary moves to the Blog Writer Agent.\n\nChecks include:\n- Minimum sentence count  \n- Presence of scientific keywords:\n  - method / approach  \n  - result / findings  \n  - conclusion / significance  \n- Detection of missing or empty summaries  \n- Flagging potential hallucinations  \n\nIssues are appended to the final output for transparency.\n\n---\n\n### 6. **Blog Writer Agent**\nTransforms technical summaries into accessible blog-style explanations:\n\n- Friendly, conversational tone  \n- Clear interpretations without losing accuracy  \n- Suitable for broad audiences  \n\nThe scientific meaning remains intact‚Äîonly the style changes.\n\n---\n\n### 7. **Orchestrator Agent**\nCoordinates the entire agent workflow:\n\n1. Receives user topic  \n2. Calls Search Agent  \n3. Passes URLs to Extraction Agent  \n4. Sends extracted text to Summarization Agent  \n5. Runs the Evaluation Agent  \n6. Sends approved summaries to Blog Writer Agent  \n7. Returns all outputs to the user  \n\nActs as the ‚Äúproject manager,‚Äù ensuring each step executes in sequence and handles missing or invalid papers gracefully.\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Section 3 ‚Äî Agent Implementations","metadata":{}},{"cell_type":"code","source":"TOP_JOURNALS = [\n    #\"nature.com\",\n    #\"nature.com/nbt\",          # Nature Biotechnology\n    #\"nature.com/nmeth\",        # Nature Methods\n    \"journals.plos.org/ploscompbiol\",\n    \"academic.oup.com/bioinformatics\",\n    \"elifesciences.org\"\n]","metadata":{"execution":{"iopub.status.busy":"2025-11-30T06:32:39.527260Z","iopub.execute_input":"2025-11-30T06:32:39.527607Z","iopub.status.idle":"2025-11-30T06:32:39.532353Z","shell.execute_reply.started":"2025-11-30T06:32:39.527586Z","shell.execute_reply":"2025-11-30T06:32:39.531071Z"},"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Search Agent with publication date extraction\nclass SearchAgent:\n    \"\"\"Searches top computational biology journals for relevant papers.\"\"\"\n\n    def search_papers(self, subject, max_results=5):\n        query_results = []\n        with DDGS() as ddgs:\n            for journal in TOP_JOURNALS:\n                query = f\"{subject} site:{journal} latest research paper\"\n                for r in ddgs.text(query, max_results=max_results):\n                    query_results.append({\n                        \"title\": r.get(\"title\"),\n                        \"link\": r.get(\"href\"),\n                        \"journal\": journal,\n                        \"date\": r.get(\"date\")  # <-- added date\n                    })\n        return query_results\n","metadata":{"execution":{"iopub.status.busy":"2025-11-30T06:32:42.066961Z","iopub.execute_input":"2025-11-30T06:32:42.067421Z","iopub.status.idle":"2025-11-30T06:32:42.074824Z","shell.execute_reply.started":"2025-11-30T06:32:42.067395Z","shell.execute_reply":"2025-11-30T06:32:42.073573Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# -------- Short Scientific Summary Prompt & Summarization Agent --------\nfrom google.generativeai import GenerativeModel\n\nSHORT_SUMMARY_PROMPT = \"\"\"\nYou are a scientific summarizer. Produce a concise scientific summary (3‚Äì4 sentences max).\n\nRequired structure (do not label sections, just write text):\n- What the paper studies\n- The main method or approach\n- Key findings or results\n- Brief implication or significance\n\nABSOLUTELY DO NOT guess content. \nIf the paper text is missing, empty, or non-scientific, return EXACTLY:\n\"SKIP\"\n\nKeep summary extremely short and factual.\n\"\"\"\n\nclass SummarizationAgent:\n    \"\"\"\n    Uses Gemini to generate short, scientific summaries of full-text papers.\n    Only returns a summary when the paper text is long enough to be meaningful.\n    \"\"\"\n    def __init__(self, model_name: str = \"gemini-2.5-flash-lite\"):\n        self.model = GenerativeModel(model_name)\n\n    def summarize_paper(self, paper_title: str, paper_text: str):\n        # Guard against missing or unusable text\n        if not paper_text:\n            return None\n\n        clean_text = paper_text.strip()\n        # Very short text is usually metadata / landing page only ‚Üí treat as no access\n        if len(clean_text) < 800:\n            return None\n\n        prompt = (\n            SHORT_SUMMARY_PROMPT\n            + \"\\n\\nPaper Title: \" + (paper_title or \"Unknown title\")\n            + \"\\n\\nPaper Text:\\n\"\n            + clean_text[:5000]\n        )\n\n        try:\n            response = self.model.generate_content(prompt)\n            summary = (response.text or \"\").strip()\n        except Exception:\n            return None\n\n        # Respect explicit SKIP instruction\n        if summary.upper().strip() == \"SKIP\":\n            return None\n\n        # Post-process: keep at most 4 sentences to enforce shortness\n        sentences = re.split(r\"(?<=[.!?])\\s+\", summary)\n        summary_short = \" \".join(sentences[:4]).strip()\n\n        return summary_short or None\n","metadata":{"execution":{"iopub.status.busy":"2025-11-30T06:32:45.163818Z","iopub.execute_input":"2025-11-30T06:32:45.164181Z","iopub.status.idle":"2025-11-30T06:32:45.172497Z","shell.execute_reply.started":"2025-11-30T06:32:45.164154Z","shell.execute_reply":"2025-11-30T06:32:45.171471Z"},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Paper Text Extraction Agent\nclass PaperTextExtractor:\n    \"\"\"\n    Fetches web pages and extracts main textual content.\n    Returns None when text is not accessible or clearly insufficient.\n    \"\"\"\n    def __init__(self, min_chars: int = 800):\n        self.min_chars = min_chars\n\n    def extract_text(self, url: str):\n        if not url:\n            return None\n        try:\n            resp = requests.get(url, timeout=20)\n            resp.raise_for_status()\n        except Exception:\n            return None\n\n        html = resp.text\n        soup = BeautifulSoup(html, \"html.parser\")\n\n        # Remove obviously non-content tags\n        for tag in soup([\"script\", \"style\", \"nav\", \"footer\", \"header\", \"noscript\"]):\n            tag.decompose()\n\n        text = soup.get_text(separator=\" \")\n        # Normalize whitespace\n        text = \" \".join(text.split())\n\n        if len(text) < self.min_chars:\n            return None\n\n        return text\n","metadata":{"execution":{"iopub.status.busy":"2025-11-30T06:32:49.450807Z","iopub.execute_input":"2025-11-30T06:32:49.451212Z","iopub.status.idle":"2025-11-30T06:32:49.458423Z","shell.execute_reply.started":"2025-11-30T06:32:49.451174Z","shell.execute_reply":"2025-11-30T06:32:49.457421Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"### Orchestrator (Conceptual)\n\nThis notebook uses a *functional orchestration* pattern rather than a\ndedicated `OrchestratorAgent` class.\n\nThe main pipeline cell:\n- Searches for papers  \n- Extracts text  \n- Summarizes using LLM  \n- Evaluates with EvaluationAgent  \n- Generates PDF  \n\nThis fulfills the role of an orchestrator without requiring a separate class.\n","metadata":{}},{"cell_type":"markdown","source":"\n### Evaluation Agent\n\nThe **Evaluation Agent** is responsible for performing lightweight quality checks\non each blog-ready summary generated by the pipeline. It verifies:\n\n- That the summary is not empty  \n- That it contains at least a minimum number of sentences (default: 3)  \n- That it mentions core scientific concepts such as *methods*, *results*, or *conclusions*  \n\nThe agent returns a simple dictionary with a boolean `is_pass` flag and a list of\n`issues`. If any issues are detected, they are appended to the end of the summary\nbefore exporting to the PDF report.\n","metadata":{}},{"cell_type":"code","source":"\n# Evaluation Agent\nclass EvaluationAgent:\n    '''\n    Agent that performs lightweight quality checks on blog-ready summaries.\n\n    It verifies:\n        - Non-empty text\n        - Minimum number of sentences (>= min_sentences)\n        - Presence of key scientific keywords: method, result, conclusion\n    '''\n\n    def __init__(self, min_sentences: int = 3):\n        self.min_sentences = min_sentences\n\n    def evaluate(self, text: str) -> Dict:\n        '''\n        Evaluate a summary and return a dict with pass/fail and issues.\n\n        Args:\n            text: The generated blog-ready summary.\n\n        Returns:\n            {\n                \"is_pass\": bool,\n                \"issues\": List[str]\n            }\n        '''\n        issues: List[str] = []\n\n        if not text or not text.strip():\n            issues.append(\"Empty summary.\")\n            return {\"is_pass\": False, \"issues\": issues}\n\n        # Rough sentence count by splitting on punctuation\n        sentences = [s.strip() for s in re.split(r\"[.!?]+\", text) if s.strip()]\n        if len(sentences) < self.min_sentences:\n            issues.append(f\"Too short: only {len(sentences)} sentence(s).\")\n\n        lowered = text.lower()\n        keywords = [\"method\", \"approach\", \"result\", \"finding\", \"conclusion\"]\n        if not any(k in lowered for k in keywords):\n            issues.append(\"Missing method/result/conclusion keywords.\")\n\n        return {\n            \"is_pass\": len(issues) == 0,\n            \"issues\": issues,\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:37:50.719151Z","iopub.execute_input":"2025-11-30T06:37:50.719667Z","iopub.status.idle":"2025-11-30T06:37:50.730441Z","shell.execute_reply.started":"2025-11-30T06:37:50.719636Z","shell.execute_reply":"2025-11-30T06:37:50.728494Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"\n# User Prompt + Prepare Agents\nsubject = input(\"What subject are you interested in? \").strip()\nif not subject:\n    raise ValueError(\"Please provide a non-empty subject.\")\n\n# Instantiate agents\nsearch_agent = SearchAgent()\nextraction_agent = PaperTextExtractor()\nsummarization_agent = SummarizationAgent()\nevaluation_agent = EvaluationAgent(min_sentences=3)\n\n# Search for candidate papers in top journals\npapers = search_agent.search_papers(subject, max_results=5)\nprint(f\"Found {len(papers)} candidate papers.\")\n","metadata":{"execution":{"iopub.status.busy":"2025-11-30T06:37:56.248903Z","iopub.execute_input":"2025-11-30T06:37:56.249475Z","iopub.status.idle":"2025-11-30T06:38:05.300166Z","shell.execute_reply.started":"2025-11-30T06:37:56.249440Z","shell.execute_reply":"2025-11-30T06:38:05.299183Z"},"trusted":true},"outputs":[{"output_type":"stream","name":"stdin","text":"What subject are you interested in?  longevity\n"},{"name":"stdout","text":"Found 15 candidate papers.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"\n# Run the summarization pipeline and generate blog-ready summaries\n\nfrom google.generativeai import GenerativeModel\n\nblog_model = GenerativeModel(\"gemini-2.5-flash\")\n\nfinal_summaries = []\nevaluation_results = []\n\nfor paper in papers:\n    try:\n        url = paper.get(\"link\")\n        title = paper.get(\"title\") or \"Untitled Paper\"\n\n        full_text = extraction_agent.extract_text(url)\n        if not full_text:\n            # Skip papers without accessible text\n            continue\n\n        # Blog-writing prompt\n        blog_prompt = f\"\"\"You are a science communicator. Write a clear, engaging, blog-ready summary \nbased ONLY on the text below.\n\nYour output must include:\n\n1. A bold title line containing the paper title  \n2. A clickable URL below it  \n3. A 2‚Äì4 paragraph blog-style explanation that covers:\n   - What the study is about\n   - Why it matters\n   - How the researchers approached the problem\n   - The key findings\n   - The broader significance\n4. The publication date\n\nDo NOT guess missing details. Focus on what can be inferred from the text.\n\nPaper Title: {title}\nPaper URL: {url}\nPaper Date: {paper.get(\"date\")}\n\nPaper Text:\n{full_text[:6000]}\n\"\"\"  # end of blog_prompt\n\n        response = blog_model.generate_content(blog_prompt)\n        blog_text = (response.text or \"\").strip()\n\n        # Evaluate the blog-ready summary\n        eval_result = evaluation_agent.evaluate(blog_text)\n        evaluation_results.append(eval_result)\n\n        # Append evaluation issues (if any) to the entry\n        entry = blog_text\n        if not eval_result[\"is_pass\"]:\n            issues_str = \"; \".join(eval_result[\"issues\"])\n            entry += f\"\\n\\n[Evaluation issues: {issues_str}]\"\n\n        final_summaries.append(entry)\n\n    except Exception as e:\n        print(f\"Skipping due to error: {e}\")\n        continue\n\n# Print blog-ready summaries\nfor s in final_summaries:\n    print(s)\n    print(\"\\n---\\n\")\n\n# Simple evaluation summary\nnum_pass = sum(1 for e in evaluation_results if e.get(\"is_pass\"))\nprint(\"Number of blog-ready summaries:\", len(final_summaries))\nprint(\"Number of summaries passing evaluation:\", num_pass)\n","metadata":{"execution":{"iopub.status.busy":"2025-11-30T06:38:12.264957Z","iopub.execute_input":"2025-11-30T06:38:12.265793Z","iopub.status.idle":"2025-11-30T06:39:18.667537Z","shell.execute_reply.started":"2025-11-30T06:38:12.265759Z","shell.execute_reply":"2025-11-30T06:39:18.666031Z"},"trusted":true},"outputs":[{"name":"stdout","text":"**Identifying longevity associated genes by integrating gene expression and curated annotations**\nhttps://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008429\n\nAging is a complex biological process, and the specific genetic mechanisms that control it are still largely a mystery. While scientists have identified some genes that influence lifespan, traditional methods of discovery‚Äîlike individually altering genes in model organisms‚Äîare often slow and expensive. Recent efforts have turned to machine learning to classify genes as either \"pro-longevity\" (extending lifespan) or \"anti-longevity\" (shortening lifespan), but it hasn't been clear which computational approaches or data types are most effective for this task.\n\nThis study aimed to address these challenges by systematically comparing different machine learning methods and data types to predict gene longevity status. Researchers evaluated five popular classification algorithms using gene ontology and gene expression data as features. They applied these methods to genes from two well-known model organisms, nematode worms (*C. elegans*) and yeast (*S. cerevisiae*), using the GenAge database as a reliable source of previously identified longevity genes for training and validation.\n\nThe key finding was that a specific algorithm, elastic net penalized logistic regression, proved particularly effective at classifying genes as pro- or anti-longevity. By leveraging this optimized approach, the team was able to make novel predictions, identifying new pro- and anti-longevity genes that had not yet been cataloged in the GenAge database.\n\nThese findings are significant because they provide a more efficient and accurate computational tool for identifying genes involved in aging. By pinpointing new candidate genes, this research can help accelerate our understanding of aging biology and potentially open doors for future studies into interventions that could impact lifespan and healthy aging.\n\nPublication Date: November 30, 2020\n\n---\n\n**The Mass-Longevity Triangle: Pareto Optimality and the Geometry of Life-History Trait Space**\nhttps://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004524\n\nUnderstanding why some mammals live much longer than others, even those of similar size, is a fundamental question in biology. Traditionally, scientists have often looked for simple linear relationships (allometric lines) between traits like mass and longevity. However, this study challenges that view, suggesting that such simple lines only explain a fraction of the variation in lifespan. This research introduces a new framework, based on Pareto optimality theory, to explore how longevity relates to other life-history traits like body mass and fecundity.\n\nTo dive deeper into this mystery, the researchers analyzed a comprehensive dataset covering the life history traits of 2105 species of endotherms (mammals and birds). They applied Pareto optimality theory, which posits that when organisms face tradeoffs in performing multiple tasks, their traits don't optimize everything; instead, they cluster into specific geometric shapes‚Äîlike polygons‚Äîin trait space. The points at the corners of these shapes represent \"archetypes,\" or species that are highly optimized for a single strategy.\n\nTheir key finding revealed that, instead of falling along a simple line, the life history traits of these species‚Äîspecifically mass and longevity‚Äîprimarily form a *triangle* when plotted on logarithmic scales. This \"Mass-Longevity Triangle\" suggests three fundamental life strategies, with bats, shrews, and whales serving as exemplars of the archetypes at its vertices. Species closer to these vertices are specialists in one strategy, while those near the center are more generalized. Interestingly, looking at the data with higher resolution, the researchers found that traits can also form a tetrahedron, adding a fourth archetypal strategy related to carnivory.\n\nThis new \"Mass-Longevity Triangle\" offers a powerful new coordinate system for comparative studies of animal longevity. It not only provides a fresh perspective on why some species live longer than others of similar mass but also demonstrates how multi-objective optimization principles can help us understand complex biological tradeoffs and infer the core strategies that shape the diversity of life on Earth. This framework can be particularly useful for future genome-scale comparative studies focusing on mammalian aging and other biological phenomena.\n\nPublished: October 14, 2015\n\n---\n\n**PIEZO1 and the mechanism of the long circulatory longevity of human red blood cells**\nhttps://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1008496&type=printable\n\nThis research paper investigates the role of a protein called PIEZO1 in determining the extended lifespan of human red blood cells as they circulate throughout the body. Understanding the specific mechanisms that allow these vital blood cells to maintain their longevity is a fundamental area of biological inquiry, contributing to our overall knowledge of human physiology.\n\nBased on the provided text, which primarily consists of publication metadata, details about how the researchers approached this problem, their specific key findings, or the broader significance of their work beyond the core subject are not available. The study's clear focus, however, is on dissecting the intricate processes that contribute to the remarkable duration of red blood cell circulation, highlighting PIEZO1 as a central component in this biological mechanism.\n\nPublication Date: 2021-03-10\n\n---\n\n**Novel feature selection methods for construction of accurate epigenetic clocks**\nhttps://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009938\n\nEpigenetic clocks are powerful tools that predict an individual's age and future health by analyzing chemical marks (methylation) at specific DNA sites called CpG sites. These clocks are crucial for measuring the effectiveness of interventions aimed at extending longevity and for screening for those that might slow or reverse aging. As the field expands, there's a growing demand for more robust and accurate clocks, and particularly for efficient methods to identify the most predictive DNA sites to include in their construction.\n\nTraditionally, epigenetic clocks have often been built using all measured CpG sites, which can be inefficient. To address this, researchers in this study applied novel feature selection methods to optimize the identification of these predictive CpG sites. Their approach involved using sophisticated combinatorial techniques, including newly adapted neural networks, genetic algorithms, and 'chained' combinations. They utilized human whole blood methylation data, encompassing approximately 470,000 CpG sites, to develop these improved clocks.\n\nThe study successfully developed several clocks that accurately predict age, achieving R2 correlation scores greater than 0.73. Notably, their most predictive clock used only 35 CpG sites and achieved an impressive R2 correlation score of 0.87. Another clock, built using the five most frequently selected CpG sites across all models, still achieved a strong R2 score of 0.83. These new clocks were rigorously validated on two external datasets, where they maintained excellent predictive accuracy and, significantly, outperformed three established epigenetic clocks (Hannum, Horvath, and Weidner). The researchers also identified gene regulatory regions associated with the selected CpGs, suggesting potential targets for future aging research.\n\nThese findings are highly significant for the field, as the developed feature selection algorithms enable the construction of accurate, generalizable epigenetic clocks using a much smaller number of CpG sites. This advancement provides important new tools, making the development of more precise and efficient age prediction clocks more accessible and robust.\n\nPublication Date: August 19, 2022\n\n---\n\n**Capturing continuous, long timescale behavioral changes in Drosophila melanogaster postural data**\nhttps://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012753\n\nAnimal behavior is incredibly complex, unfolding across many timescales‚Äîfrom short, seconds-long actions to daily rhythms and even lifelong changes. Understanding these intricate sequences can offer crucial insights into an animal's health, reproductive fitness, and internal states like hunger or neural activity. Recent advancements in computer vision and machine learning are revolutionizing our ability to quantitatively measure these behaviors, providing deeper insights into their presence and the complex temporal patterns they form. This study aimed to leverage these technologies to capture continuous, long-timescale behavioral changes in *Drosophila melanogaster*, commonly known as fruit flies, to build a clearer picture of their activity patterns.\n\nTo achieve this, researchers employed a high-resolution, long-term monitoring approach. They continuously recorded individual fruit flies at 100 frames per second for up to seven days in simple, featureless arenas. Utilizing the deep learning framework SLEAP, they processed an enormous dataset comprising nearly 2 billion pose instances from 47 individual flies, constructing a detailed full-body postural dataset. From this rich data, they identified stereotyped behaviors such as grooming, proboscis extension, and locomotion. These behavioral \"ethograms\" were then used to analyze how the flies' actions varied across different times of day and over several days within the experiment.\n\nThe study yielded several key findings, significantly enhancing our understanding of *D. melanogaster* behavior. They discovered distinct daily patterns across all stereotyped behaviors, providing specific details on trends in various grooming modalities, the duration of proboscis extensions, and locomotion speed, thereby adding to existing knowledge about the fruit fly's circadian cycle. A particularly notable finding was that the hour immediately following dawn represents a unique period in the flies‚Äô daily behavioral rhythm, with the composition of behaviors during this time tracking well with other indicators of health, such as locomotion speed and the proportion of time spent moving versus resting.\n\nFurthermore, the research revealed that the well-known morning and evening spikes in overall activity levels are actually composed of different sets of behaviors, suggesting they may serve distinct biological purposes. This comprehensive method, along with the resulting data and analysis, offers a novel and clearer perspective on *D. melanogaster* behavior across various timescales. The new features uncovered hint at unexplored underlying biological mechanisms, and the innovative method developed for continuous, high-resolution behavioral monitoring holds significant potential for future studies examining the relationship between these behaviors and longevity and overall health.\n\nPublication Date: February 3, 2025\n\n---\n\n**Organelle proteomic profiling reveals lysosomal heterogeneity in association with longevity**\nhttps://elifesciences.org/articles/85214\n\nLysosomes are vital cellular compartments, acting as central hubs that integrate metabolism and signaling pathways. Both these lysosomal functions have been linked to regulating longevity, yet how lysosomes adjust their protein composition to influence the aging process has remained unclear. This understanding is crucial because lysosomal dysfunction is associated with various serious diseases, including lysosomal storage disorders, Alzheimer's, Parkinson's, and certain types of cancer.\n\nTo investigate this, researchers employed a powerful technique called deep proteomic profiling. They systematically analyzed lysosome-associated proteins connected to four different longevity mechanisms. Their approach also included comparative proteomic analyses of lysosomes from different tissues and those marked with specific identifiers in *C. elegans*, a commonly used model organism. This method allowed them to unbiasedly identify proteins associated with lysosomes.\n\nThe study uncovered several key findings. They discovered the lysosomal recruitment of AMP-activated protein kinase (AMPK) and nucleoporin proteins, demonstrating their necessity for longevity when lysosomal fat breakdown (lipolysis) increases. Furthermore, the research revealed significant lysosomal heterogeneity‚Äîmeaning differences in composition‚Äîacross various tissues. They also observed an increased enrichment of the Ragulator complex on specific Cystinosin-positive lysosomes. This work collectively reveals the diversity of the lysosomal proteome across multiple scales.\n\nThese insights provide valuable resources for understanding how the dynamic changes in lysosomal proteins contribute to signal transduction, communication between different organelles, and ultimately, an organism's lifespan. The developed tool and associated proteomics datasets represent a significant resource for the *C. elegans* community, promising to stimulate new studies into the regulation and broader role of lysosomes at the organismal level and offering new perspectives on how these organelles control specific homeostasis responses.\n\nPublication Date: February 19, 2024\n\n---\n\nNumber of blog-ready summaries: 6\nNumber of summaries passing evaluation: 6\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Save blog-ready summaries to PDF (Unicode-safe, no duplicate titles)\nfrom fpdf import FPDF\nimport unicodedata\nimport re\n\ndef clean_unicode(text):\n    \"\"\"Convert unicode to closest ASCII and remove unsupported chars.\"\"\"\n    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n\ndef remove_duplicate_title(entry):\n    \"\"\"\n    Prevent any repeated title/URL blocks.\n    The entry already contains title + date + URL from Gemini.\n    \"\"\"\n    entry = entry.strip()\n    entry = re.sub(r'\\n{3,}', '\\n\\n', entry)\n    return entry\n\nif len(final_summaries) == 0:\n    print(\"No summaries available to save.\")\nelse:\n    pdf = FPDF()\n    pdf.set_auto_page_break(auto=True, margin=15)\n    pdf.add_page()\n    pdf.set_font(\"Arial\", size=12)\n\n    # üî• This prints only what Gemini already produced ‚Äî NO extra title\n    pdf.multi_cell(0, 10, clean_unicode(f\"Blog-Ready Summaries for: {subject}\\n\\n\"))\n\n    for entry in final_summaries:\n        cleaned_entry = clean_unicode(remove_duplicate_title(entry))\n\n        # **THIS is the key line:** We write ONLY the summary itself\n        pdf.multi_cell(0, 10, cleaned_entry + \"\\n\\n\")\n\n    pdf_path = \"/kaggle/working/literature_review.pdf\"\n    pdf.output(pdf_path)\n\n    print(\"PDF saved to:\", pdf_path)\n","metadata":{"execution":{"iopub.status.busy":"2025-11-30T06:40:30.672495Z","iopub.execute_input":"2025-11-30T06:40:30.672890Z","iopub.status.idle":"2025-11-30T06:40:30.696698Z","shell.execute_reply.started":"2025-11-30T06:40:30.672865Z","shell.execute_reply":"2025-11-30T06:40:30.695289Z"},"trusted":true},"outputs":[{"name":"stdout","text":"PDF saved to: /kaggle/working/literature_review.pdf\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"\n# Conclusion\n\nThis multi-agent system automates the process of:\n- Searching top computational biology journals  \n- Fetching the latest papers  \n- Summarizing them using Gemini  \n- Producing blog-ready articles  \n\nIt demonstrates:\n‚úî Workflow orchestration  \n‚úî Multi-agent collaboration  \n‚úî Real-world scientific utility  \n‚úî Google Gemini integration  \n\n","metadata":{}},{"cell_type":"code","source":"# Simple check helper for final_summaries (optional)\nif \"final_summaries\" in globals():\n    print(f\"final_summaries is defined with {len(final_summaries)} entries.\")\nelse:\n    print(\"final_summaries is not defined yet. Run the pipeline cells first.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:40:36.155142Z","iopub.execute_input":"2025-11-30T06:40:36.155498Z","iopub.status.idle":"2025-11-30T06:40:36.161385Z","shell.execute_reply.started":"2025-11-30T06:40:36.155474Z","shell.execute_reply":"2025-11-30T06:40:36.160297Z"}},"outputs":[{"name":"stdout","text":"final_summaries is defined with 6 entries.\n","output_type":"stream"}],"execution_count":33}]}